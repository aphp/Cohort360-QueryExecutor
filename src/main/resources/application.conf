app {
    enableCache = false
    jobs {
        threads = 100
    }
    back {
      url: ${?DJANGO_CALLBACK_URL}
      authToken: ${?SJS_TOKEN}
    }
    query {
        useSourcePopulation = true
        useSourcePopulation = ${?USE_SOURCE_POPULATION}
    }
    server {
        port = 8090
        port = ${?SJS_APP_PORT}
    }
    cohortCreationLimit: 20000
    cohortCreationLimit: ${?COHORT_CREATION_LIMIT}
    cohortTableName: ${?COHORT_TABLE_NAME}
    cohortTableItemsName: ${?COHORT_TABLE_ITEMS_NAME}
    defaultResolver: solr
    defaultResolver: ${?DEFAULT_RESOLVER}

}

spark {
    master = "local[*]"
    master = ${?SPARK_MASTER}
    driver {
        host = "localhost"
        host = ${?SPARK_DRIVER_HOST}
        port = 4000
        port = ${?SPARK_DRIVER_PORT}
    }
    executor {
        memory = ${?SPARK_EXECUTOR_MEMORY}
    }
}

postgres {
      host = ${?PG_HOST}
      database = ${?PG_DB}
      schema = ${?PG_SCHEMA}
      user = ${?PG_USER}
      port = ${?PG_PORT}
}

solr {
    zk = ${?SOLR_ZK}
    maxTry = 1
    rows = 10000
    commitWithin = 10000
    authFile = "solr_auth.txt"
}

fhir {
    url = ${?FHIR_URL}
    accessToken = ${?FHIR_ACCESS_TOKEN}
}
